{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKvFmtLX2khBZ4TBi2G7Zc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotharisanjana/CMPE258_DeepLearning_Spring2023/blob/main/Assignment_1/DL_Codelab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MNIST hand written digits classification**"
      ],
      "metadata": {
        "id": "4qZhZp_tsXWJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Thx9qaBVQma"
      },
      "outputs": [],
      "source": [
        "# Parameters  \n",
        "\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "steps_per_epoch = 60000//BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paths of data files\n",
        "\n",
        "train_images_path  = 'gs://mnist-public/train-images-idx3-ubyte'\n",
        "train_labels_path  = 'gs://mnist-public/train-labels-idx1-ubyte'\n",
        "val_images_path = 'gs://mnist-public/t10k-images-idx3-ubyte'\n",
        "val_labels_path = 'gs://mnist-public/t10k-labels-idx1-ubyte'"
      ],
      "metadata": {
        "id": "9tBizX5JdzTt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "CsPAvchYeDbo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions for reading data\n",
        "\n",
        "def read_image(image_bytes):\n",
        "    image = tf.io.decode_raw(image_bytes, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/256.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "\n",
        "def read_label(label_bytes):\n",
        "    label = tf.io.decode_raw(label_bytes, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "\n",
        "def load_dataset(image_path, label_path):\n",
        "    image = tf.data.FixedLengthRecordDataset(image_path, 28*28, header_bytes=16)\n",
        "    image = image.map(read_image, num_parallel_calls=16)\n",
        "    label = tf.data.FixedLengthRecordDataset(label_path, 1, header_bytes=8)\n",
        "    label = label.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((image, label))\n",
        "    return dataset\n",
        "\n",
        "def get_training_dataset(image_path, label_path, batch_size):\n",
        "    dataset = load_dataset(image_path, label_path)\n",
        "    dataset = dataset.cache() \n",
        "    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(image_path, label_path):\n",
        "    dataset = load_dataset(image_path, label_path)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.batch(10000, drop_remainder=True)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "1zDpoX8AkIXD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and validation datasets\n",
        "\n",
        "training_dataset = get_training_dataset(train_images_path, train_labels_path, BATCH_SIZE)\n",
        "validation_dataset = get_validation_dataset(val_images_path, val_labels_path)"
      ],
      "metadata": {
        "id": "wJGnxFHMh2cY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simply one-layer neural network"
      ],
      "metadata": {
        "id": "xxBHjVAHpXYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28*28,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "# Defining model architecture\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pxz-07Mi8zW",
        "outputId": "571effe4-90c6-45f5-c3d1-327aeaf6596e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpC3tNOAqogA",
        "outputId": "2236ca17-3071-44dc-97c8-7e7918673de5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "468/468 [==============================] - 8s 9ms/step - loss: 1.2500 - accuracy: 0.7194 - val_loss: 0.8049 - val_accuracy: 0.8316\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.7118 - accuracy: 0.8418 - val_loss: 0.6072 - val_accuracy: 0.8634\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.5856 - accuracy: 0.8595 - val_loss: 0.5268 - val_accuracy: 0.8754\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.5259 - accuracy: 0.8687 - val_loss: 0.4815 - val_accuracy: 0.8816\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.4886 - accuracy: 0.8748 - val_loss: 0.4517 - val_accuracy: 0.8868\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.4625 - accuracy: 0.8795 - val_loss: 0.4305 - val_accuracy: 0.8889\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.4435 - accuracy: 0.8827 - val_loss: 0.4143 - val_accuracy: 0.8932\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.4288 - accuracy: 0.8857 - val_loss: 0.4017 - val_accuracy: 0.8953\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.4166 - accuracy: 0.8882 - val_loss: 0.3911 - val_accuracy: 0.8968\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.4066 - accuracy: 0.8900 - val_loss: 0.3824 - val_accuracy: 0.8987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on validation dataset\n",
        "\n",
        "probabilities = model.predict(validation_dataset, steps=1)\n",
        "print(probabilities.shape)\n",
        "print(probabilities)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqz5RqB4r9zv",
        "outputId": "d2a51287-fab4-48bc-8122-c09b3c4ae9df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 485ms/step\n",
            "(10000, 10)\n",
            "[[7.8748626e-04 8.1971093e-06 3.1598753e-04 ... 9.8955309e-01\n",
            "  3.6115607e-04 6.0557751e-03]\n",
            " [2.3060651e-02 8.3497004e-04 7.6156962e-01 ... 1.3204278e-05\n",
            "  2.7070902e-02 5.9919650e-05]\n",
            " [7.4396067e-04 9.3207967e-01 1.8221354e-02 ... 7.5208955e-03\n",
            "  1.4428624e-02 3.2247140e-03]\n",
            " ...\n",
            " [2.7504033e-05 1.6964381e-04 4.0811874e-04 ... 1.7022252e-02\n",
            "  2.6384143e-02 7.6570340e-02]\n",
            " [1.2521682e-02 1.7651666e-02 4.4961357e-03 ... 6.9619492e-03\n",
            "  3.9220786e-01 4.4354559e-03]\n",
            " [1.6698792e-03 3.6459807e-07 2.6247371e-03 ... 1.0788053e-06\n",
            "  3.7591813e-05 7.9703286e-06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding dense layers to existing network"
      ],
      "metadata": {
        "id": "N8-rino8pjWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding more layers to the neural network\n",
        "\n",
        "model_ = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(200, activation='sigmoid'),\n",
        "      tf.keras.layers.Dense(60, activation='sigmoid'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "# Defining model architecture\n",
        "model_.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_.summary()\n",
        "\n",
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u01R4Wylsg80",
        "outputId": "0a14a4b6-755a-4c54-9442-640a2a5b5070"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 200)               157000    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 60)                12060     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.2713 - accuracy: 0.2242 - val_loss: 2.2299 - val_accuracy: 0.4526\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.1981 - accuracy: 0.4691 - val_loss: 2.1571 - val_accuracy: 0.5881\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.1143 - accuracy: 0.5918 - val_loss: 2.0560 - val_accuracy: 0.6517\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 1.9954 - accuracy: 0.6421 - val_loss: 1.9126 - val_accuracy: 0.6749\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 1.8316 - accuracy: 0.6671 - val_loss: 1.7233 - val_accuracy: 0.6878\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 1.6304 - accuracy: 0.6862 - val_loss: 1.5099 - val_accuracy: 0.7044\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 1.4238 - accuracy: 0.7102 - val_loss: 1.3101 - val_accuracy: 0.7200\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 1.2416 - accuracy: 0.7350 - val_loss: 1.1467 - val_accuracy: 0.7429\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 1.0984 - accuracy: 0.7562 - val_loss: 1.0204 - val_accuracy: 0.7722\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.9860 - accuracy: 0.7755 - val_loss: 0.9224 - val_accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Altering activation function and optimizer"
      ],
      "metadata": {
        "id": "TRDv5iRupx2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing sigmoid wtih relu activation function and sgd with adam optimizer\n",
        "\n",
        "model_ = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(200, activation='relu'),\n",
        "      tf.keras.layers.Dense(60, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "# Defining model architecture\n",
        "model_.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_.summary()\n",
        "\n",
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE_Zcj86xQ2v",
        "outputId": "cd1c1ea2-7856-4447-adab-b37abd20fabf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 200)               157000    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 60)                12060     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.3079 - accuracy: 0.9136 - val_loss: 0.1457 - val_accuracy: 0.9552\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1261 - accuracy: 0.9626 - val_loss: 0.1140 - val_accuracy: 0.9668\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0829 - accuracy: 0.9753 - val_loss: 0.0844 - val_accuracy: 0.9728\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0606 - accuracy: 0.9820 - val_loss: 0.0769 - val_accuracy: 0.9766\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0475 - accuracy: 0.9862 - val_loss: 0.0760 - val_accuracy: 0.9773\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0357 - accuracy: 0.9897 - val_loss: 0.0757 - val_accuracy: 0.9766\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.0934 - val_accuracy: 0.9733\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0763 - val_accuracy: 0.9787\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0912 - val_accuracy: 0.9738\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.0855 - val_accuracy: 0.9796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using decaying learning rate"
      ],
      "metadata": {
        "id": "dv49Dzj4p3vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lr decay function\n",
        "def lr_decay(epoch):\n",
        "  return 0.01 * math.pow(0.6, epoch)\n",
        "\n",
        "# lr schedule callback\n",
        "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)"
      ],
      "metadata": {
        "id": "zDGjaXda0hD5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using decaying learning rate\n",
        "\n",
        "model_ = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(200, activation='relu'),\n",
        "      tf.keras.layers.Dense(60, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "# Defining model architecture\n",
        "model_.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_.summary()\n",
        "\n",
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKSIh4_92G2-",
        "outputId": "ea133a9e-41c1-4302-a820-890e1b32cea3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 200)               157000    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 60)                12060     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,670\n",
            "Trainable params: 169,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.2174 - accuracy: 0.9337 - val_loss: 0.1523 - val_accuracy: 0.9540 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0922 - accuracy: 0.9723 - val_loss: 0.1050 - val_accuracy: 0.9686 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.0847 - val_accuracy: 0.9754 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.0823 - val_accuracy: 0.9771 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.0768 - val_accuracy: 0.9791 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0754 - val_accuracy: 0.9803 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0745 - val_accuracy: 0.9811 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0751 - val_accuracy: 0.9809 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0758 - val_accuracy: 0.9815 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0761 - val_accuracy: 0.9818 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making the neural network with 4 layers"
      ],
      "metadata": {
        "id": "htvN8NQPqRpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding more layers to the neural network \n",
        "\n",
        "model_ = tf.keras.Sequential([\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(200, activation='relu'),\n",
        "      tf.keras.layers.Dense(100, activation='relu'),\n",
        "      tf.keras.layers.Dense(60, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "# Defining model architecture\n",
        "model_.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_.summary()\n",
        "\n",
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y6of9Y22Nwh",
        "outputId": "51e6a426-f7d6-4d7b-c909-63cc7fdec283"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 200)               157000    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               20100     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 60)                6060      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 183,770\n",
            "Trainable params: 183,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.2511 - accuracy: 0.9238 - val_loss: 0.1746 - val_accuracy: 0.9487 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0988 - accuracy: 0.9704 - val_loss: 0.1245 - val_accuracy: 0.9670 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0567 - accuracy: 0.9830 - val_loss: 0.1004 - val_accuracy: 0.9738 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.0863 - val_accuracy: 0.9785 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0810 - val_accuracy: 0.9806 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.0813 - val_accuracy: 0.9814 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.0839 - val_accuracy: 0.9817 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0853 - val_accuracy: 0.9814 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0862 - val_accuracy: 0.9818 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0868 - val_accuracy: 0.9818 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding dropout to control overfitting"
      ],
      "metadata": {
        "id": "P7N8m9nLvGZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "  [\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(200, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.25),\n",
        "      tf.keras.layers.Dense(100, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.25),\n",
        "      tf.keras.layers.Dense(60, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.25),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1jNIkd2pH2h",
        "outputId": "ecfebc82-5d25-441f-fad3-e0e6351ec210"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 200)               157000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 100)               20100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 60)                6060      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 60)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 183,770\n",
            "Trainable params: 183,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzUK9AcEvNcP",
        "outputId": "ddd22366-3d16-419a-d757-70a5e6b10496"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.2297 - accuracy: 0.9408 - val_loss: 0.1746 - val_accuracy: 0.9576 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9750 - val_loss: 0.1153 - val_accuracy: 0.9714 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0549 - accuracy: 0.9836 - val_loss: 0.0971 - val_accuracy: 0.9765 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.0937 - val_accuracy: 0.9782 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.0946 - val_accuracy: 0.9786 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.0974 - val_accuracy: 0.9794 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.1006 - val_accuracy: 0.9791 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.1024 - val_accuracy: 0.9787 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.1037 - val_accuracy: 0.9787 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.1045 - val_accuracy: 0.9787 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convolutional Neural Network"
      ],
      "metadata": {
        "id": "8e-EVXoPjvRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=12, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=24, strides=2, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=6, filters=32, strides=2, activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()\n",
        "\n",
        "# Fit model\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeLfEfbEjtwd",
        "outputId": "a58991c1-a659-466e-bf13-25ddcf619447"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 24)        10392     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 32)          27680     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 288)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                2890      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,082\n",
            "Trainable params: 41,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.1894 - accuracy: 0.9549 - val_loss: 0.1590 - val_accuracy: 0.9642 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0766 - accuracy: 0.9787 - val_loss: 0.1128 - val_accuracy: 0.9741 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0450 - accuracy: 0.9870 - val_loss: 0.1075 - val_accuracy: 0.9753 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.1011 - val_accuracy: 0.9776 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.1041 - val_accuracy: 0.9773 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.1066 - val_accuracy: 0.9776 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.1085 - val_accuracy: 0.9787 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.1102 - val_accuracy: 0.9788 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.1111 - val_accuracy: 0.9787 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.1118 - val_accuracy: 0.9788 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN with padding and more dense layers"
      ],
      "metadata": {
        "id": "qDjmxxkqkwlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(kernel_size=3, filters=12, activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=24, activation='relu', padding='same', strides=2),\n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=32, activation='relu', padding='same', strides=2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(200, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFCdKk6ikkC_",
        "outputId": "1a641d0b-d004-4777-dbbf-4c235cd822d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_1 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 12)        120       \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 24)        10392     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 32)          27680     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 200)               313800    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 354,002\n",
            "Trainable params: 354,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1710 - accuracy: 0.9606 - val_loss: 0.1807 - val_accuracy: 0.9620 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0805 - accuracy: 0.9789 - val_loss: 0.1279 - val_accuracy: 0.9715 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.1031 - val_accuracy: 0.9760 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0303 - accuracy: 0.9913 - val_loss: 0.1055 - val_accuracy: 0.9774 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.1057 - val_accuracy: 0.9785 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.1122 - val_accuracy: 0.9777 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.1158 - val_accuracy: 0.9780 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.1178 - val_accuracy: 0.9783 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.1193 - val_accuracy: 0.9783 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.1203 - val_accuracy: 0.9785 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding dropout layer to above architecture to reduce overfitting since validation loss is shooting up"
      ],
      "metadata": {
        "id": "ykfJ3NaxlKbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(kernel_size=3, filters=12, activation='relu', padding='same'),\n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=24, activation='relu', padding='same', strides=2),\n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=32, activation='relu', padding='same', strides=2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(200, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.4),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "# Define architecture\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Fit model\n",
        "\n",
        "history = model_.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoPC1Isuk5kp",
        "outputId": "89db1cbd-8af3-41d0-f7e2-a03cd2e55f9a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_2 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 12)        120       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 24)        10392     \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 32)          27680     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 200)               313800    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 354,002\n",
            "Trainable params: 354,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.1606 - accuracy: 0.9641 - val_loss: 0.1620 - val_accuracy: 0.9648 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0650 - accuracy: 0.9836 - val_loss: 0.1160 - val_accuracy: 0.9748 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.9899 - val_loss: 0.1177 - val_accuracy: 0.9785 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.1214 - val_accuracy: 0.9779 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.1326 - val_accuracy: 0.9770 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.1368 - val_accuracy: 0.9770 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.1402 - val_accuracy: 0.9768 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.1429 - val_accuracy: 0.9765 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.1443 - val_accuracy: 0.9767 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.1452 - val_accuracy: 0.9768 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gHnTYlUGlcfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Batch normalization"
      ],
      "metadata": {
        "id": "OVNoMHIGpGl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(kernel_size=3, filters=12, use_bias=False, padding='same'),\n",
        "      tf.keras.layers.BatchNormalization(center=True, scale=False),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=24, use_bias=False, padding='same', strides=2),\n",
        "      tf.keras.layers.BatchNormalization(center=True, scale=False),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      tf.keras.layers.Conv2D(kernel_size=6, filters=32, use_bias=False, padding='same', strides=2),\n",
        "      tf.keras.layers.BatchNormalization(center=True, scale=False),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(200, use_bias=False),\n",
        "      tf.keras.layers.BatchNormalization(center=True, scale=False),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgyfNmfspH3E",
        "outputId": "471ed0a0-b789-48bc-81a3-34feeb9398ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_3 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 12)        108       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 12)       36        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 28, 12)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 24)        10368     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 14, 14, 24)       72        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 14, 14, 24)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 7, 7, 32)          27648     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 7, 7, 32)         96        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 200)               313600    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 200)              600       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 200)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 354,538\n",
            "Trainable params: 354,002\n",
            "Non-trainable params: 536\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGcpkBT_pTpT",
        "outputId": "45cdae4a-c135-4516-898d-7b03bd15a0e5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/10\n",
            "468/468 [==============================] - 11s 11ms/step - loss: 0.1198 - accuracy: 0.9635 - val_loss: 0.1942 - val_accuracy: 0.9435 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.006.\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 0.0276 - val_accuracy: 0.9910 - lr: 0.0060\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0036.\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.0250 - val_accuracy: 0.9918 - lr: 0.0036\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0021599999999999996.\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0231 - val_accuracy: 0.9921 - lr: 0.0022\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001296.\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0187 - val_accuracy: 0.9938 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0007775999999999998.\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0212 - val_accuracy: 0.9936 - lr: 7.7760e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0004665599999999999.\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 5s 11ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0183 - val_accuracy: 0.9943 - lr: 4.6656e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00027993599999999994.\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0180 - val_accuracy: 0.9940 - lr: 2.7994e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00016796159999999993.\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0179 - val_accuracy: 0.9939 - lr: 1.6796e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00010077695999999997.\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0179 - val_accuracy: 0.9941 - lr: 1.0078e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-2uO6yaqiWS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}